[["index.html", "Teoria da Probabilidade Chapter 1 INTRODUÇÃO", " Teoria da Probabilidade Bruno Wavrzenczak - Cristian Pessatti dos Anjos - Caio Gomes Alves - Anderson Amorim 2024-03-14 Chapter 1 INTRODUÇÃO prob prob prob "],["revisão---operadores-lógicos.html", "Chapter 2 REVISÃO - OPERADORES LÓGICOS", " Chapter 2 REVISÃO - OPERADORES LÓGICOS EM PROGRESSO "],["revisão---teoria-dos-conjuntos.html", "Chapter 3 REVISÃO - TEORIA DOS CONJUNTOS 3.1 Conjuntos 3.2 Intervalos 3.3 Operações com Conjuntos 3.4 Exercícios Resolvidos", " Chapter 3 REVISÃO - TEORIA DOS CONJUNTOS 3.1 Conjuntos Chamaremos de conjunto (usualmente representado por alguma letra maiúscula) uma coleção de elementos de algum espaço maior chamado universo (representado aqui pela letra maiúscula U) Exemplo: \\[ \\begin{align*} &amp;U = \\mathbb{R}\\\\ &amp;A = \\{0,2,4,6,8,10\\} = \\{x = 2k\\;|\\;k=0,1,2,3,4,5\\}\\\\ &amp;B = \\{...,-3,-2,-1,0,1,2,3,...\\} = Z\\\\ &amp;C = \\{x \\in U\\;|\\;-1&lt;x \\le 2\\} = (-1,2\\rbrack \\end{align*} \\] 3.2 Intervalos \\[ \\begin{align*} &amp;\\lbrack a,b\\rbrack = \\{x\\in R\\;|\\; a\\le x\\le b,\\; a&lt;b\\}\\\\ &amp;(a,b) = \\{x \\in R\\;|\\;a&lt;x&lt;b,\\;a&lt;b\\}\\\\ \\end{align*} \\] Se \\(a = b\\), então temos um intervalo degenerado, também chamado de singleton \\(\\;\\lbrack a,a\\rbrack = \\{a\\}\\) 3.3 Operações com Conjuntos 3.3.1 União (ou Conjunção): \\(A \\cup B = \\{x \\in U\\;|\\;x\\in A\\vee x\\in B\\}\\) Exemplo: \\[ \\begin{align*} &amp;A=\\{2,4,6,8,10\\}\\\\ &amp;B=\\{0,1,2,3,4\\}\\\\ &amp;A\\cup B=\\{0,1,2,3,4,6,8,10\\} \\end{align*} \\] 3.3.2 Interseção (ou Disjunção): \\(A\\cap B = \\{x\\in U\\;|\\;x\\in A\\wedge x\\in B\\}\\) Exemplo: \\[ \\begin{align*} &amp;A=\\{2,4,6,8,10\\}\\\\ &amp;B=\\{0,1,2,3,4\\}\\\\ &amp;A\\cap B=\\{2,4\\} \\end{align*} \\] 3.3.3 Complementar (ou Negação): \\(A^{c} = \\{x\\in U\\;|\\;x\\notin A\\}\\) Exemplo: \\[ \\begin{align*} &amp;U=\\{1,2,3,4,5\\}\\\\ &amp;A=\\{3,4\\}\\\\ &amp;A^{c}=\\{1,2,5\\} \\end{align*} \\] 3.3.4 Leis de Morgan: Sejam A e B conjuntos em um universo, então vale que: \\[ \\begin{align*} &amp;I) (A\\cup B)^{c} = A^{c}\\cap B^{c}\\\\ &amp;II) (A\\cap B)^{c} = A^{c}\\cup B^{c} \\end{align*} \\] Generalizando: Sejam \\(A_1,A_2,...,A_n\\;(n\\in N)\\) conjuntos que pertencem a um mesmo universo, então vale que: \\[ \\begin{align*} &amp;I)\\;(\\overset{n}{\\underset{i=1}{\\cup}} A_i)^{c}=\\overset{n}{\\underset{i=1}{\\cap}} A_i^c\\quad \\text{ou}\\quad(A_1\\cup A_2\\;...\\;\\cup\\;A_n)^{c}=(A_1^{c}\\cap A_2^{c}\\;...\\;\\cap\\;A_n^c)\\\\ &amp;II)\\;(\\overset{n}{\\underset{i=1}{\\cap}} A_i)^{c}=\\overset{n}{\\underset{i=1}{\\cup}} A_i^{c}\\quad \\text{ou}\\quad(A_1\\cap A_2\\;...\\;\\cap\\;A_n)^{c}=(A_1^{c}\\cup A_2^{c}\\;...\\;\\cup \\;A_n^c) \\end{align*} \\] obs: também funciona para infinitos conjuntos. Demonstração: (Magalhães, pág.3) Queremos demonstrar que \\((\\overset{n}{\\underset{i=1}{\\cup}} A_i)^{c}=\\overset{n}{\\underset{i=1}{\\cap}} A_i^c\\). Quando lidamos com igualdade entre conjuntos, mostraremos que cada um dos conjuntos está contido no outro, portanto precisamos verificar duas condições: \\((\\overset{n}{\\underset{i=1}{\\cup}} A_i)^{c}\\subset\\overset{n}{\\underset{i=1}{\\cap}} A_i^c\\quad\\)e\\(\\quad(\\overset{n}{\\underset{i=1}{\\cup}} A_i)^{c}\\supset\\overset{n}{\\underset{i=1}{\\cap}} A_i^c\\) Seja \\(\\omega\\) um elemento qualquer pertencente ao universo, então supomos que \\(\\omega\\in(\\overset{n}{\\underset{i=1}{\\cup}} A_i)^{c}\\), portanto \\(\\omega\\notin(\\overset{n}{\\underset{i=1}{\\cup}} A_i)\\), o que também leva a conclusão de que \\(\\omega\\notin A_i\\) para todo \\(i\\). Logo \\(\\omega\\in A_i^{c}\\) para todo \\(i\\) e, portanto \\(\\omega\\in\\overset{n}{\\underset{i=1}{\\cap}} A_i^c\\) De forma análoga, podemos facilmente verificar a segunda condição e, portanto, demonstramos a primeira lei de Morgan. A demonstração da segunda lei pode ser feita da mesma forma. 3.4 Exercícios Resolvidos (Magalhães, seção 1.2) 1. Sendo A, B e C subconjuntos quaisquer, expresse em notação matemática os conjuntos cujos elementos: a. Estão em A e B, mas não em C. b. Não estão em nenhum deles. c. Estão, no máximo, em dois deles. d. Estão em A, mas no máximo em um dos outros. e. Estão na intersecção dos três conjuntos e no complementar de A. Soluções: a. não estar em \\(C\\) significa estar no complementar de \\(C\\), portanto podemos reescrever a questão da seguinte forma: “Estão em \\(A\\) e \\(B\\) e no complementar de \\(C\\)”. Quando dizemos que um elemento está em um conjunto E em outro, estamos falando de uma interseção, portanto a solução é: \\(A\\cap B\\cap C^{c}\\) b. não estar em nenhum deles é a negação de estar em algum dos conjuntos. Logo a solução é a seguinte: \\((A\\cup B\\cup C)^{c}\\) ou, utilizando a primeira lei de Morgan: \\(A^{c}\\cap B^{c}\\cap C^{c}\\) c. o elemento não pode estar nos três conjuntos, o que é a negação de estar nos três conjuntos: \\((A\\cap B\\cap C)^{c}\\) d. isso significa estar em \\(A\\) e não estar na interseção dos outros dois conjuntos: \\(A\\cap(B\\cap C)^c\\) e. para estar nos três conjuntos precisa também estar em \\(A\\), o que torna a interseção com \\(A^c\\) um conjunto vazio \\((\\phi)\\) "],["experimentos-e-eventos-probabilísticos.html", "Chapter 4 EXPERIMENTOS E EVENTOS PROBABILÍSTICOS 4.1 Experimento Aleatório 4.2 Eventos 4.3 \\(\\sigma\\)-álgebra", " Chapter 4 EXPERIMENTOS E EVENTOS PROBABILÍSTICOS 4.1 Experimento Aleatório Iremos denominar pela letra grega \\(\\varepsilon\\) qualquer experimento aleatório realizado sob condições fixas. Vamos também chamar de espaço amostral (\\(\\Omega\\)) o conjunto que contém todos os resultados possíveis de \\(\\varepsilon\\). Aqui, “resultado possível” significa um resultado elementar e indivisível do experimento \\(\\varepsilon\\). Exemplos: (i) seja \\(\\varepsilon_1\\): lançar um dado honesto e observar o resultado (face voltada para cima) \\[ \\begin{align*} &amp;\\Omega_1=\\{1,2,3,4,5,6\\}\\\\ \\end{align*} \\] (ii) seja \\(\\varepsilon_2\\): medir a tensão de uma rede de alta tensão a cada minuto por uma hora. \\[ \\begin{align*} &amp;\\Omega_2=[0,+\\infty)\\\\ \\end{align*} \\] (iii) seja \\(\\varepsilon_3\\): escolher um ponto do círculo unitário. \\[ \\begin{align*} &amp;\\Omega_3=\\{(x,y)\\in\\mathbb{R}\\;|\\;x^2+y^2\\le1\\}\\\\ \\end{align*} \\] 4.2 Eventos Eventos nada mais são do que conjuntos contendo elementos do espaço amostral que satisfazem dada condição. Em outras palavras, um evento é um subconjunto do espaço amostral. Exemplo: Para \\(\\varepsilon_1\\), podemos ter, por exemplo, os seguintes eventos: \\[ \\begin{align*} &amp;A=\\text{&quot;oberva-se um número par&quot;} = \\{2,4,6\\}\\\\ &amp;B=\\text{&quot;oberva-se o número 2&quot;} = \\{2\\}\\\\ &amp;C=\\text{&quot;oberva-se um número maior ou igual a 4&quot;} = \\{4,5,6\\}\\\\ &amp;C=\\text{&quot;oberva-se um ímpar&quot;} = \\{1,3,5\\}\\\\ \\end{align*} \\] Vamos denominar o conjunto \\(\\phi\\) a um evento impossível, e \\(\\Omega\\) a um evento certo. Exemplo: Para \\(\\varepsilon_1\\): \\(A\\cap D = \\phi\\rightarrow\\) evento impossível. \\(A\\cup D = \\Omega\\rightarrow\\) evento certo. DEFINIÇÃO: seja \\(\\Omega\\) o espaço amostral para o experimento \\(\\varepsilon\\), todo subconjunto \\(A\\subset\\Omega\\) será chamado evento, como já mencionado, \\(\\phi\\) é o evento impossível e \\(\\Omega\\) é o evento certo. Se \\(\\omega\\in\\Omega\\), o evento \\(\\{\\omega\\}\\) é dito elementar. 4.3 \\(\\sigma\\)-álgebra Para conseguirmos definir uma probabilidade precisaremos de uma classe especial de eventos chamada \\(\\sigma\\)-álgebra, que representaremos pelo símbolo \\(\\mathbb{A}\\). DEFINIÇÃO: seja \\(\\mathbb{A}\\) uma família de subconjuntos de \\(\\Omega\\) tal que: (i): \\(\\Omega\\in\\mathbb{A}\\). (ii): Se \\(A\\in\\mathbb{A}\\), então \\(A^c\\in\\mathbb{A}\\). (iii): Se \\(A_1,A_2,...\\;\\in\\mathbb{A}\\), então \\(\\overset{\\infty}{\\underset{i=1}{\\cup}}A_i\\in\\mathbb{A}\\). Nesse caso diremos que \\(\\mathbb{A}\\) é uma \\(\\sigma\\)-álgebra sobre \\(\\Omega\\). obs: Baseado em (i) e (ii), também podemos afirmar que \\(\\phi\\in\\mathbb{A}\\), já que \\(\\phi\\) é o complementar de \\(\\Omega\\). Exemplos: Para \\(\\varepsilon_1\\), \\(\\Omega=\\{1,2,3,4,5,6\\}\\). Seja \\(\\mathbb{A}_1=\\{\\{1\\},\\{1,2\\},\\{4,5,6\\},\\Omega,\\phi\\}\\). A condição (i) está satisfeita pois \\(\\Omega\\in\\mathbb{A}_1\\) A condição (ii) não está satisfeita pois os complementares de vários conjuntos não estão em \\(\\mathbb{A}\\) A condição (iii) não está satisfeita porque nem toda união de conjuntos dentro de \\(\\mathbb{A}\\) está dentro de \\(\\mathbb{A}\\). Agora, seja \\(\\mathbb{A}_2=\\{\\{1,2\\},\\{3,4,5,6\\},\\Omega,\\phi\\}\\) Em \\(\\mathbb{A}_2\\) podemos facilmente verificar que as três condições foram satisfeitas. "],["probabilidade.html", "Chapter 5 PROBABILIDADE 5.1 Definição de uma Probabilidade 5.2 Espaço de Probabilidade 5.3 Propriedades de uma Probabilidade", " Chapter 5 PROBABILIDADE 5.1 Definição de uma Probabilidade Existem varias formas de definir uma medida de probabilidade. 5.1.1 Definição Clássica de Probabilidade Suponha que \\(\\Omega\\) é finito e os pontos amostrais são equiprováveis. Então define-se: \\[ \\begin{align*} &amp;P(A) = \\frac{\\#(A)}{\\#(\\Omega)} \\end{align*} \\] Exemplo: para \\(\\varepsilon_1\\), \\(\\Omega = \\{1,2,3,4,5,6\\}\\), \\(A = \\{2,4,6\\}\\), \\(B = \\{2\\}\\), \\(C = \\{4,5,6\\}\\) \\[ \\begin{align*} &amp;P(A) = \\frac{\\#(A)}{\\#(\\Omega)} = \\frac{3}{6} = \\frac{1}{2} \\\\ &amp;P(B) = \\frac{\\#(B)}{\\#(\\Omega)} = \\frac{1}{6} \\\\ &amp;P(C) = \\frac{\\#(C)}{\\#(\\Omega)} = \\frac{3}{6} = \\frac{1}{2} \\end{align*} \\] 5.1.2 Definição Geométrica de Probabilidade Seja \\(\\varepsilon_2\\): escolher aleatoriamente um ponto do intervalo (0,1). \\[ \\begin{align*} &amp;\\Omega = (0,1) &amp;P(A) = \\frac{comp(A)}{comp(\\Omega)} \\end{align*} \\] \\(\\varepsilon_3\\) escolher um ponto no círculo unitário. \\[ \\begin{align*} &amp;\\Omega = \\{(x,y)\\;\\epsilon\\;\\mathbb{R}²\\;/\\;x²+y²\\le1\\} \\quad A = \\{(x,y)\\;\\epsilon\\;\\mathbb{R}²\\;/\\;x²+y²\\le\\frac{1}{4}\\} \\\\ &amp;P(A) = \\frac{área(A)}{área(\\Omega)} = \\frac{\\pi\\cdot\\frac{1}{4}}{\\pi} = \\frac{1}{4} \\end{align*} \\] Em geral \\(P(A) = \\frac{volume(A)}{volume(\\Omega)}\\) obs: Quando o \\(\\Omega\\) é contínuo, a probabilidade de qualquer ponto é 0. 5.1.3 Definição Frequentista de Probabilidade \\(\\varepsilon\\): Lançar uma moeda, não necessariamente honesta e registramos a ocorrência de cara. \\[ \\begin{align*} &amp;A = \\text{ocorrer cara} \\\\ &amp;n = \\text{número de lançamentos} \\\\ &amp;P(A) = \\frac{1}{n}\\cdot(\\text{número de ocorrência de A}) \\end{align*} \\] 5.1.4 Definição Axiomática de Probabilidade Uma medida de probabilidade é uma função que satisfaz os três axiomas a seguir: \\[ \\begin{align*} &amp;A_x1: P(A)\\ge 0 \\\\ &amp;A_x2:P(\\Omega) = 1 \\\\ &amp;A_x3:(\\sigma\\text{-aditividade}):Se\\;A_1,A_2,...\\text{são disjuntos então,}\\;P(\\overset{\\infty}{\\underset{i=1}{\\cup}}A_i) = \\overset{\\infty}{\\underset{i=1}{\\Sigma}}P(A_i) \\end{align*} \\] 5.2 Espaço de Probabilidade Um espaço de probabilidade é um trio (\\(\\Omega,\\mathbb{A},P\\)) onde: \\[ \\begin{align*} &amp;\\Omega\\text{ é um conjunto não-vazio} \\\\ &amp;\\mathbb{A} \\text{ é uma } \\sigma\\text{-álgebra de subconjuntos de }\\Omega \\\\ &amp;P\\text{ é uma probabilidade em }\\mathbb{A} \\end{align*} \\] 5.3 Propriedades de uma Probabilidade \\[ \\begin{align*} &amp;P_1:\\;P(A^c) = 1-P(A) \\\\ &amp;P_2:\\;0\\le P(A)\\le 1 \\\\ &amp;P_3:\\;P(B)=P(B\\cap A)+P(B\\cap A^c) \\\\ &amp;P_4:\\;\\text{Se } A \\subset B \\rightarrow P(A)\\le P(B) \\\\ &amp;P_5:\\;P(\\overset{n}{\\underset{i=1}{\\cup}}A_i)\\le \\overset{n}{\\underset{i=1}{\\Sigma}}P(A_i) \\\\ &amp;P_6:\\;P(\\overset{\\infty}{\\underset{i=1}{\\cup}}A_i)\\le \\overset{\\infty}{\\underset{i=1}{\\Sigma}}P(A_i) \\\\ &amp;P_7:\\;\\text{(Continuidade de probabilidade) Se existe uma}\\text{sequência }A_n\\text{ tal que }A_n \\uparrow A \\text{ então }\\\\ &amp;P(A_n) \\uparrow P(A).\\text{Analogamente, se }A_n \\downarrow A \\text{ entâo } P(A_n) \\downarrow P(A)\\\\ \\\\ &amp;P_8:\\;P(A\\cup B) = P(A) + P(B) - P(A\\cap B). \\\\ &amp;P(A\\cup B\\cup C) = P(A) + P(B) + P(C) - P(A\\cap B) - P(A\\cap C) - P(B\\cap C) + P(A\\cap B\\cap C) \\end{align*} \\] "],["probabilidade-condicional.html", "Chapter 6 PROBABILIDADE CONDICIONAL 6.1 Definição de Probabilidade Condicional 6.2 Teorema da Multiplicação 6.3 Partição de Omega 6.4 Teorema da Probabilidade Total 6.5 Teorema de Bayes", " Chapter 6 PROBABILIDADE CONDICIONAL 6.1 Definição de Probabilidade Condicional Lembremos do experimento \\(\\varepsilon_1\\): lançar um dado. \\[ \\begin{align*} &amp;\\Omega = \\{1,2,3,4,5,6\\} \\\\ &amp;\\text{Seja A, sair número par } = \\{2,4,6\\} \\text{ e B sair número maior que 3 } =\\{4,5,6\\} \\\\ &amp;\\text{Vimos que }P(A) = \\frac{\\#(A)}{\\#(\\Omega)} = \\frac{1}{2} \\\\ &amp;\\text{A probabilidade de A, sabendo que ocorreu B, agora será }P(A) = \\frac{\\#(A\\cap B)}{\\#(B)} = \\frac{2}{3} \\end{align*} \\] Definição: Sejam A e B eventos aleatórios em \\(\\mathbb{A}\\). Define-se a probabilidade condicional de A dado B como \\(P(A|B)\\). \\[ \\begin{align*} &amp;P(A|B) = \\frac{P(A\\cap B)}{P(B)} \\text{ se } P(B) &gt; 0 \\end{align*} \\] Se \\(P(B) = 0, P(A|B) \\text{ é arbitrário. Geralmente, nesse caso define-se P(A|B) = P(A)}\\). Importante: \\(P(qualquer coisa|B)\\) é realmente uma medida de probabilidade, logo satisfaz todos os axiomas e propriedades de uma probabilidade. Exemplos: \\[ \\begin{align*} &amp;\\bullet P(\\Omega|B) \\overset{def}{=} \\frac{P(\\Omega\\cap B)}{P(B)} = \\frac{P(B)}{P(B)} = 1 \\\\ &amp;\\bullet P((A\\cup B)|C) = \\frac{P((A\\cup B)\\cap C)}{P(C)} = \\frac{P((A\\cap C)\\cup (B\\cap C))}{P(C)} = \\frac{P(A\\cap C)}{P(C)} + \\frac{P(B\\cap C)}{P(C)} \\\\ &amp;\\bullet P(A|B) = \\frac{P(A\\cap B)}{P(B)} \\text{ , também } P(B|A) =\\frac{P(B\\cap A)}{P(A)} = \\frac{P(A\\cap B)}{P(B)} \\\\ &amp;\\bullet P(A\\cap B) = P(A|B)\\cdot P(B) = P(B|A)\\cdot P(A) \\\\ &amp;\\bullet P(A\\cap B\\cap C) = P(C|A\\cap B)\\cdot P(B|A)\\cdot P(A) \\end{align*} \\] 6.2 Teorema da Multiplicação Os dois últimos resultados do exemplo anterior podem ser generalizados (teorema da multiplicação): \\[ \\begin{align*} &amp;P(A_1\\cap A_2\\cap...\\cap A_n) = P(A_1)\\cdot P(A_2|A_1)...P(A_n|A_1\\cap A_2\\cap...\\cap A_{n-1}) \\\\ &amp;\\forall A_1,A_2,...,A_n\\;\\epsilon \\mathbb{A},\\;n=2,3,... \\end{align*} \\] Exemplo: Selecionar três cartas de um baralho, ao acaso e sem reposição. Qual a probabilidade de tirar 3 reis? \\[ \\begin{align*} &amp;\\text{Seja }A_i\\text{ tirar um rei na i-ésima retirada. }i=(1,2,3) \\\\ &amp;P(A_1\\cap A_2\\cap A_3) = P(A_1)\\cdot P(A_2|A_1)\\cdot P(A_3|A_1\\cap A_2) = \\frac{4}{52}\\cdot \\frac{3}{51}\\cdot \\frac{2}{50} \\approx 0,000181 \\end{align*} \\] 6.3 Partição de Omega Definição: Sejam \\(A_1,A_2,...\\) subconjuntos de \\(\\Omega\\). Diremos que os \\(A_i\\)’s formam uma partição de \\(\\Omega\\) se: \\[ \\begin{align*} &amp;I)\\;A_i\\cap A_j = \\phi\\;, \\forall i \\neq j \\;\\text{(disjuntos)} \\\\ &amp;II)\\;\\underset{i}{\\cup}A_i = \\Omega \\end{align*} \\] 6.4 Teorema da Probabilidade Total Seja \\(A_1,A_2,...\\) uma partição de \\(\\Omega\\), então: \\[ \\begin{align*} &amp;P(B)=\\underset{i}{\\Sigma}P(A_i)\\cdot P(B|A_i), \\forall B \\;\\epsilon\\; \\mathbb{A} \\end{align*} \\] 6.5 Teorema de Bayes Seja \\(A_1,A_2,...\\) uma partição de \\(\\Omega\\), então: \\[ \\begin{align*} &amp;P(A_i|B) = \\frac{P(B|A_i)\\cdot P(A_i)}{\\underset{j}{\\Sigma}P(B|A_j)\\cdot P(A_j)}\\;,\\;\\forall B\\; \\epsilon\\; \\mathbb{A},\\; (i\\text{ fixo}) \\end{align*} \\] Exemplo: Experimento de duas etapas ou composto. Suponha que uma caixa contenha três moedas, duas honestas e uma de duas caras. Retirar uma moeda ao acaso e joga-la.Qual a probabilidade da moeda selecionada ter sido a de duas caras, dado que o resultado foi cara? \\[ \\begin{align*} &amp;\\text{Vamos definir os eventos:} \\\\ &amp;A_1:\\text{moeda retirada é honesta} \\\\ &amp;A_2:\\text{moeda retirada é de duas caras} \\\\ &amp;B:\\text{resultado é cara} \\\\ \\\\ &amp;P(A_2|B) = \\frac{P(B|A_2)\\cdot P(A_2)}{P(B|A_1)\\cdot P(A_1)+P(B|A_2)\\cdot P(A_2)} = \\frac{1\\cdot \\frac{1}{3}}{\\frac{1}{2}\\cdot\\frac{2}{3}+1\\cdot\\frac{1}{3}} = \\frac{\\frac{1}{3}}{\\frac{2}{3}} = \\frac{1}{2} \\end{align*} \\] "],["variáveis-aleatórias.html", "Chapter 7 VARIÁVEIS ALEATÓRIAS 7.1 Definição de uma Variável Aleatória 7.2 Função de Distribuição 7.3 Tipos de Variáveis Aleatórias", " Chapter 7 VARIÁVEIS ALEATÓRIAS 7.1 Definição de uma Variável Aleatória Quando realizamos um experimento aleatório existem algumas características numéricas que são registradas. Por exemplo: número de caras em \\(n\\) lançamentos de uma moeda, tempo de vida de um componente, salário, idade, etc. em um questionário sócio econômico. Vamos dizer, informalmente, que uma variável aleatória é uma característica numérica de um experimento aleatório. Exemplo: Seja \\(\\varepsilon\\): lançar uma moeda honesta três vezes e registrar o resultado. \\[ \\begin{align*} &amp;\\Omega=\\{ \\overset{\\omega_1}{(c,c,c)}, \\overset{\\omega_2}{(c,c,\\overline c)}, \\overset{\\omega_3}{(c,\\overline c,c)}, \\overset{\\omega_4}{(\\overline c,c,c)}, \\overset{\\omega_5}{(\\overline c,\\overline c,c)}, \\overset{\\omega_6}{(\\overline c,c,\\overline c)}, \\overset{\\omega_7}{(c,\\overline c,\\overline c)}, \\overset{\\omega_8}{(\\overline c,\\overline c,\\overline c)}, \\}\\\\ \\\\ &amp;\\mathbb{A}=\\mathcal{P}(\\Omega)\\\\ \\\\ &amp;p(\\omega_i)=\\frac18,\\; i=1,...,8\\\\ \\end{align*} \\] Defina a função \\(X(\\omega_1):\\) número de caras em \\(\\omega_i\\) Assim: \\(X(\\omega_1)=3,\\;X(\\omega_2)=2,...,\\;X(\\omega_8)=0\\) Podemos escrever \\(X\\in\\{0,1,2,3\\}\\) Definição: Uma variável aleatória X em um espaço de probabilidade \\((\\Omega,\\mathbb A,P)\\) é uma função real definida sobre \\(\\Omega\\) tal que o evento \\([X\\le x]=\\{\\omega\\in\\Omega/X(\\omega)\\le x,\\forall x\\in\\mathbb R\\}\\) é um evento aleatório, ou seja \\([X\\le x]\\in\\mathbb A\\) No exemplo anterior: - Seja \\(x=-1:\\;[X\\le-1]=\\phi\\in\\mathbb A\\) - Seja \\(x&lt;0:\\;[X\\le-1]=\\phi\\in\\mathbb A\\) - Seja \\(x=0:\\;[X\\le0]=\\{\\omega_8\\}\\in\\mathbb A\\) - Seja \\(x=\\pi:\\;[X\\le\\pi]=\\Omega\\in\\mathbb A\\) - Seja \\(x=1,83:\\;[X\\le1,83]=\\{\\omega_5,\\omega_6,\\omega_7,\\omega_8\\}\\in\\mathbb A\\) 7.2 Função de Distribuição A função de distribuição de uma variável aleatória \\(X\\), representada por \\(F_X\\) (ou apenas \\(F\\) se não houver problemas de interpretação), é definida como: \\[ \\begin{align*} &amp;F_X(x)=P(X\\le x),\\;\\forall x\\in\\mathbb R \\end{align*} \\] obs: \\(F_X\\) também é chamada função de distribuição acumulada (FDA) 7.2.1 Propriedades de uma F.D. Uma função \\(F\\) será função distribuição de alguma variável aleatória \\(X\\) se: 1. \\(F\\) é não decrescente, i.e., se \\(x&lt;y\\) então \\(F(x)\\le F(y)\\) 2. \\(F\\) é contínua a direita, i.e., se \\(X_n\\downarrow x\\) então \\(F(x_n)\\downarrow F(x)\\) 3. Se \\(X_n\\downarrow-\\infty\\rightarrow F(x_n)\\downarrow0\\) e se \\(X_n\\uparrow+\\infty\\rightarrow F(x_n)\\uparrow1\\). Isso é geralmente simbolizado como: \\(F(-\\infty)=0\\) e \\(F(+\\infty)=1\\) 7.3 Tipos de Variáveis Aleatórias 7.3.1 Discreta Definição: uma variável aleatória \\(X\\) em \\((\\Omega,\\mathbb A,P)\\) será chamada discreta se ela assume um número finito ou enumerável de valores, i.e., se existe um conjunto finito ou enumerável \\(\\{x_1,x_2,...\\}\\subset\\mathbb R\\) (Os valores de uma v.a. discreta não necessariamente serão inteiros) tal que \\(X(\\omega)\\in\\{x_1,x_2,...\\};\\;\\forall\\omega\\in\\Omega\\) A função \\(p_X(x_i)=p(x_i)\\) definida por \\(p(x_i)=P(X=x_i),\\;i=1,2,...\\) é chamada função de probabilidade de \\(X\\). Para encontrarmos a função distribuição a partir de uma função de probabilidade, podemos fazer o seguinte processo: \\[ \\begin{align*} &amp;F_X(x)=\\sum_{i/x_i\\le x}P(X=x_i)=\\sum_{i/x_i\\le x}p(x_i), \\text{ pois }[X\\le x_i]=\\underset{i/x_i\\le x}{\\cup}[X=x_i] \\end{align*} \\] 7.3.2 Contínua Definição: uma variável aleatória \\(X\\) em \\((\\Omega,\\mathbb A,P)\\) será chamada contínua se existe uma função \\(f(x)\\ge0\\) chamada função densidade de \\(X\\) tal que: \\[ \\begin{align*} &amp;F_X(x)=\\int_{-\\infty}^xf(t)dt,\\;\\forall x\\in\\mathbb R \\end{align*} \\] Proposição: Uma função \\(f(x)\\ge0\\) será densidade de alguma variável aleatória \\(X\\) se, e somente se \\(\\int_{-\\infty}^{+\\infty}f(x)dx=1\\). Em suma, para saber se uma variável aleatória possui densidade, podemos utilizar o seguinte critério prático: \\(X\\) terá densidade se: 1. \\(F_X\\) é contínua 2. \\(F_X\\) é derivável por partes, ou seja, \\(F_X\\) existe no interior de um número finito ou enumerável de intervalos fechados, cuja união é a reta real. "],["esperança-e-variância.html", "Chapter 8 ESPERANÇA E VARIÂNCIA 8.1 Definição de Esperança 8.2 Propriedades de Esperança", " Chapter 8 ESPERANÇA E VARIÂNCIA 8.1 Definição de Esperança 8.1.1 Variável Discreta Seja \\(X\\) uma variável aleatória discreta em \\(\\{x_1,x_2,...\\}\\) com f.p \\(p_x(x)\\). Define-se a esperança (ou valor esperado ou média) de \\(X\\) como: \\[ \\begin{align*} &amp;E(x) = \\underset{i}{\\sum}x_i\\cdot p_x(x_i) = \\underset{i}{\\sum}x_i\\cdot P(X=x_i) \\end{align*} \\] Exemplo: Seja \\(X\\) dado por: \\(P(X= -2)=0,2\\;,\\;P(X=-1)=0,3\\;,\\;P(X=0)=0,3\\text{ e } P(X=2)=0,2\\). Vamos imaginar que temos uma barra sem peso que tem massas distribuidas nos pontos \\(-2,-1,0,2\\). O centro de gravidade da barra pode ser calculado como: \\[ \\begin{align*} &amp;G=\\overset{4}{\\underset{i=1}{\\sum}}x_i p_i =(-2)(0,2)+(-1)(0,3)+(0)(0,3)+(2)(0,2) = -0,3 \\end{align*} \\] 8.1.2 Variável Contínua Definição: Seja \\(X\\) uma v.a contínua com densidade f. Defini-se a esperança de \\(X\\) como: \\[ \\begin{align*} &amp;E(X)=\\overset{+\\infty}{\\underset{-\\infty}{\\int}}xf(x)dx \\end{align*} \\] Exemplo: Seja \\(X\\) com F.D: \\[ \\begin{align*} &amp;F(x)= \\left\\{ \\begin{array}{ll} 0,&amp;x&lt;0\\\\ x,&amp;0\\le x\\le 1\\\\ 1,&amp;x&gt;1 \\end{array} \\right. \\\\\\\\ &amp;f(x)= \\left\\{ \\begin{array}{ll} 1,&amp;0\\le x\\le 1\\\\ 0,&amp; c.c \\end{array} \\right. \\\\\\\\ &amp;E(X)= \\overset{+\\infty}{\\underset{-\\infty}{\\int}}xf(x)dx=\\overset{0}{\\underset{-\\infty}{\\int}}x0dx\\;+\\; \\overset{1}{\\underset{0}{\\int}}x1dx\\;+\\;\\overset{+\\infty}{\\underset{1}{\\int}}x0dx\\;\\\\ &amp;=\\overset{1}{\\underset{0}{\\int}}xdx=\\frac{x²}{2}\\Bigg|_{0}^{1}=\\frac{1}{2} \\end{align*} \\] 8.2 Propriedades de Esperança \\[ \\begin{align*} &amp;E_1:\\;\\text{Se }X=c\\text{, então }E(X)=c\\\\ &amp;E_2:\\;\\text{Se }X\\le Y\\text{, então }E(X)\\le E(Y)\\\\ &amp;E_3:\\;E(aX+b)=aE(X)+b,\\;b\\;\\epsilon\\;\\mathbb{R}\\\\ &amp;\\qquad\\;\\text{e também: }E(aX+bY)=aE(X)+bE(Y)\\\\ &amp;E_4:\\;\\text{Desigualdade de Jensen: Seja }\\Large\\varphi\\normalsize\\text{ uma função convexa,}\\\\ &amp;\\qquad\\;\\text{se a v.a é integravel }E(X)&lt;\\infty\\text{, então:}\\\\ &amp;\\qquad\\;E[\\Large\\varphi\\normalsize(x)]\\ge\\Large\\varphi\\normalsize(E(X)) \\end{align*} \\] Um resultado importante: \\[ \\begin{align*} &amp;\\text{A função }\\Large\\varphi\\normalsize(x) = x² \\text{ é convexa, então pela }E_4:\\\\ &amp;E[X²]\\ge(E[X])²\\\\ &amp;\\text{Note que: }E[X²]-(E[X])²\\ge0\\text{. Essa diferença será importante para a próxima definição} \\end{align*} \\] 8.2.1 Definição de Variância Define-se a variância de uma v.a \\(X\\) como \\(Var[X]=E[X²]-(E[X])²\\) "],["função-geradora-de-momentos-e-função-característica.html", "Chapter 9 FUNÇÃO GERADORA DE MOMENTOS E FUNÇÃO CARACTERÍSTICA 9.1 Definição de Função Geradora de Momentos 9.2 Definição de Função Característica 9.3 Propriedades da Função Característica", " Chapter 9 FUNÇÃO GERADORA DE MOMENTOS E FUNÇÃO CARACTERÍSTICA 9.1 Definição de Função Geradora de Momentos Definição: Seja \\(X\\) uma v.a integrável. Define-se a Função Geradoras de momentos de \\(X\\) (FGM) como: \\[ \\begin{align*} &amp;M_x(t) = E(e^{tx}) = \\left\\{ \\begin{array}{ll} \\underset{x}{\\sum}e^{tx}P(X=x),&amp;X\\text{ discreto}\\\\ \\overset{+\\infty}{\\underset{-\\infty}{\\int}}e^{tx}f(x)dx,&amp;X\\text{ contínua} \\end{array} \\right.\\\\ &amp;\\text{sendo t um parâmetro real} \\end{align*} \\] Exemplo Discreto: Seja \\(X\\) tal que \\(P(X=-1)=P(X=1)=\\frac{1}{2}\\) \\[ \\begin{align*} &amp;M_x(t) = \\underset{x\\epsilon\\{-1,1\\}}{\\sum}e^{tx}P(X=x)=e^{-t}P(X=-1)+e^{t}P(X=1)=\\frac{e^{-t}+e^{t}}{2} \\end{align*} \\] Exemplo Contínuo: Seja \\(X\\) uma v.a com densidade \\(f(x)=e^{-x},\\;x\\ge0\\) \\[ \\begin{align*} &amp;M_x(t)=\\overset{+\\infty}{\\underset{-\\infty}{\\int}}e^{tx}f(x)dx=\\overset{+\\infty}{\\underset{0}{\\int}}e^{tx}e^{-x}dx\\\\ &amp;\\qquad\\;\\;=\\overset{+\\infty}{\\underset{0}{\\int}}e^{-(1-t)}dx=-\\frac{1}{(1-t)}e^{-(1-t)x}\\Bigg|_{0}^{+\\infty}\\frac{1}{1-t}(1-0)\\\\ &amp;\\qquad\\;\\;=\\frac{1}{1-t},\\;t&lt;1 \\end{align*} \\] Notar que para FGM de \\(X\\) existir foi necessario restringir os valores de t. Uma dificuldade de FGM é que nem sempre ela existe, mesmo numa vizinhaça de zero Teorema: Suponha que a FGM de \\(X\\) exista para \\((t)&lt;t_0.(t_0&gt;0)\\) Então o k-ésimo momento de \\(X\\) existe e pode set encontrado como: \\[ \\begin{align*} &amp;E(X^k)=M^{(k)}_X(t)\\Bigg|_{t=0} = \\frac{\\delta^k}{\\delta t^k}M_X(t)\\Bigg|_{t=0}\\quad,\\;k=1,2,3,... \\end{align*} \\] Esse resultado justifica o nome da FGM, pois de alguma forma ela gera todos os momentos de \\(X\\) Exemplo: \\[ \\begin{align*} &amp;M_x(t)=\\frac{e^{-t}+e^t}{2}\\\\ &amp;M&#39;_X(t)=\\frac{1}{2}(-e^{-t}+e^t) \\rightarrow M&#39;_X(0)=\\frac{1}{2}(-e^{-0}+e⁰)=0\\\\ &amp;\\text{Logo }E(X)=M&#39;_x(0)=0 \\end{align*} \\] Também: \\[ \\begin{align*} &amp;M&#39;&#39;_X(t)=\\frac{1}{2}(e^{-t}+e^t) \\rightarrow M&#39;&#39;_X(0)=\\frac{1}{2}(e^{-0}+e^{0})=1=E(X²)\\\\ &amp;Var[X]=E[X²]-(E[X])²=1-0=1 \\end{align*} \\] Teorema: Se duas v.a’s têm FGM que existam, e são iguais, entao elas têm a mesma distribuição. Teorema: Sejam \\(X\\) e \\(Y\\) v.a’s independentes. Então: \\[ \\begin{align*} &amp;M_{X+Y}(t)=M_X(T)M_Y(t)\\\\ &amp;\\text{desde que todas as FGM envolvidas existam} \\end{align*} \\] obs: \\[ \\begin{align*} &amp;1)\\text{ Esse resultado serve para encontrar a distribuição da soma de duas v.a&#39;s independentes}\\\\ &amp;2)\\text{ Esse resultado pode ser estendido para n v.a&#39;s independentes: se }X_1,X_2,...,X_n\\text{ são independentes, então:}\\\\ &amp;\\quad M_{X_1+X_2+...+X_n}(t)=\\prod_{i=1}^nM_{X_i}(t) \\end{align*} \\] Teorema: Seja \\(M_X(t)\\) a FGM de \\(X\\). Defina \\(Y=ax+b\\). Então: \\[ \\begin{align*} &amp;M_Y(t)=M_{ax+b}(t)=e^{bt}M_X(at),\\quad a,b\\in\\mathbb{R} \\end{align*} \\] Prova: \\[ \\begin{align*} &amp;M_Y(t)=E\\left[e^{tY}\\right]=E[e^{t(aX+b)}]=E[e^{taX+bt}]=E[e^{bt}e^{atX}]\\\\ &amp;=e^{bt}E[e^{atX}]=e^{bt}M_X(at) \\end{align*} \\] 9.2 Definição de Função Característica Dadas duas v.a’s reais \\(X\\) e \\(Y\\) no mesmo experimento podemos definir uma v.a complexa como: \\[ \\begin{align*} &amp;Z=X+iY\\\\ &amp;\\text{Notar que: }e^{iX}=\\cos{X} +i\\sin{X} \\end{align*} \\] Definição: Seja \\(X\\) uma v.a real qualquer. Defini-se a Função Característica (FC) de \\(X\\) como: \\[ \\begin{align*} &amp;\\Large\\varphi\\normalsize_X(t)=E\\left[\\cos (tX)\\right]+iE\\left[\\sin (tX)\\right] \\end{align*} \\] Notar que, a diferença da FGM, \\(\\Large\\varphi\\normalsize(t)\\in \\mathbb{C}\\). A grande vantagem da FC sobre a FGM é que a FC, SEMPRE existe. Notar também que se a FGM existir então \\(\\Large\\varphi\\normalsize_X(t)=M_X(it)\\) Para calcular na prática a FC podemos utilizar: \\[ \\begin{align*} &amp;\\Large\\varphi\\normalsize_X(t)= \\left\\{ \\begin{array}{ll} \\sum e^{itx}P(X=x),&amp;X\\text{ discreto}\\\\ \\overset{+\\infty}{\\underset{-\\infty}{\\int}}e^{itx}f(x)dx,&amp;X\\text{ contínuo} \\end{array} \\right. \\end{align*} \\] 9.3 Propriedades da Função Característica \\[ \\begin{align*} &amp;FC1:\\;\\Large\\varphi\\normalsize_X(0)=1\\\\ &amp;FC2:\\;|\\Large\\varphi\\normalsize_X(t)|\\le1,\\;\\forall t\\in\\mathbb{R}\\\\ &amp;FC3:\\;\\Large\\varphi\\normalsize_X(t)=\\Large\\varphi\\normalsize_X(-t)\\\\ &amp;FC4:\\;\\Large\\varphi\\normalsize_X\\text{ é uniformemente contínua na reta.}\\\\ &amp;FC5:\\;\\text{Se X e Y são v.a&#39;s independentes, então:}\\\\ &amp;\\qquad\\quad\\Large\\varphi\\normalsize_{X+Y}(t)=\\Large\\varphi\\normalsize_X(t)\\Large\\varphi\\normalsize_Y(t)\\\\ &amp;FC6:\\;\\text{A FC de uma v.a X determina a função distribuição de X}\\\\ &amp;\\qquad\\quad\\text{Fórmula de Inversão: } F(y)-F(x)=\\frac{1}{2\\pi}\\lim_{u\\rightarrow\\infty}\\overset{u}{\\underset{-u}{\\int}}\\frac{e^{-itx}-e^{-ity}}{it}\\Large\\varphi\\normalsize_X(t)\\\\ &amp;FC7:\\;\\text{A v.a X tem distribuição simétrica em torno de zero sse }\\Large\\varphi\\normalsize_X(t)\\text{ é real},\\;\\forall t\\\\ &amp;FC8:\\;\\text{Se } Y=aX+b,\\;a,b\\in\\mathbb{R}\\text{ então }\\Large\\varphi\\normalsize_X(t)=e^{itb}\\Large\\varphi\\normalsize_X(at)\\\\ &amp;FC9:\\;\\text{Se }E[|X|^n]&lt;\\infty,\\text{ então }\\Large\\varphi\\normalsize_X\\text{ possui n derivadas contínuas}\\\\ &amp;\\qquad\\quad E[X^k]=\\frac{1}{i^k}\\Large\\varphi\\normalsize_X^{(k)}(0)\\\\ &amp;\\qquad\\quad\\text{(ou seja, a FC, também é uma espécie de geradora de momentos)} \\end{align*} \\] "],["modelos-de-probabilidade.html", "Chapter 10 MODELOS DE PROBABILIDADE 10.1 Modelos Discretos 10.2 Modelos Contínuos", " Chapter 10 MODELOS DE PROBABILIDADE Como visto no capítulo 6, descreve-se uma variável aleatória pela sua Função de Distribuição ou pela sua Função de Densidade/Probabilidade. Aqui, estudaremos alguns tipos de variáveis aleatórias conhecidas e suas aplicações. 10.1 Modelos Discretos 10.1.1 Modelo Uniforme Discreto Esse modelo é utilizado quando temos um número finito de possibilidades, no qual todas elas são equiprováveis. Seja X uma variável aletória que segue o modelo uniforme discreto, então escreveremos: \\(X\\sim U_d(A)\\), onde \\(A\\) é o conjunto de valores possíveis para a variável: \\(A=\\{x_1,x_2,\\;...\\;,x_n\\}\\). Função de Probabilidade: \\(p(x_i)=\\frac{1}{n}\\;,\\;i=1,2,...,n\\) Exemplo: Vamos lançar um dado honesto e a variável aletória X será a face observada. É fácil observar que \\(X\\sim U_d(\\{1,2,3,4,5,6\\})\\): \\(p(x_i)=\\frac{1}{6}\\) 10.1.2 Modelo de Bernoulli Esse modelo é utilizado quando temos apenas duas opções, que chamaremos de fracasso e sucesso, ou 0 e 1. Notação: \\(X\\sim Bernoulli(p)\\) onde \\(p\\) é a probabilidade de sucesso. Função de Probabilidade: \\(p(1)=P(X=1)=p\\) \\(p(0)=P(X=0)=1-p\\) Exemplo: Lançar uma moeda equilibrada e observar o lado virado para cima. \\[ \\begin{align*} &amp;X = \\begin{cases} 1 &amp; \\text{, se cara}\\\\ 0 &amp; \\text{, se coroa} \\end{cases} \\end{align*} \\] Como a probabilidade de sair cara é \\(\\frac{1}{2}\\), então \\(X\\sim Bernoulli(\\frac{1}{2})\\). 10.1.3 Modelo Binomial Suponha que vamos realizar \\(n\\) ensaios de Bernoulli independentes e de probabilidade \\(p\\) e X será a quantidade de sucessos obtidas nos \\(n\\) ensaios. Então diremos que X segue uma Binomial de parâmetros \\(n\\) e \\(p\\): \\(X\\sim Bin(n,p)\\) Função de Probabilidade: \\(p(x)={n\\choose x}\\cdot p^x\\cdot(1-p)^{n-x}\\) Exemplo: Suponha que vamos lançar 100 moedas equilibradas e X será a quantidade de caras observadas. \\(X\\sim Bin(100, \\frac{1}{2})\\) Qual a probabilidade de sair exatamente 60 caras? \\[ \\begin{align*} p(60)={100\\choose 60}\\cdot\\Big(\\frac{1}{2}\\Big)^{60}\\cdot\\Big(\\frac{1}{2}\\Big)^{40} = \\end{align*} \\] 10.1.4 Modelo Geométrico Suponha que vamos realizar uma sequência de ensaios de Bernoulli até acontecer o primeiro sucesso, e seja X a quantidade de fracassos antes do primeiro sucesso. Então X segue uma geométrica de parâmetro \\(p\\), onde \\(p\\) é a probabilidade de sucesso. Notação: \\(X\\sim Geo(p)\\) Função de Probabilidade: \\(p(x)=p(1-p)^x,\\;x=0,1,2,...\\) Exemplo: Em uma linha de produção de alta precisão, assim que um item apresenta defeito, a linha de produção é interrompida para manutenção. A probabilidade de ter um defeito em um dia é de \\(\\frac{1}{100}\\). Qual a probabilidade de termos uma manutenção no sexto dia? \\[ \\begin{align*} p(5)=\\Big(\\frac{1}{100}\\Big)\\cdot\\Big(\\frac{99}{100}\\Big)^5= \\end{align*} \\] 10.1.5 Modelo Poisson Suponha que nosso interesse seja contar a quantidade de eventos que ocorreram em uma unidade de medida. Chamaremos de \\(\\lambda\\) a taxa de ocorrência do evento por unidade de medida, e diremos que \\(X\\) segue um modelo Poisson de parâmetro \\(\\lambda\\). Notação: \\(X\\sim Pois(\\lambda)\\) Função de Probabilidade: \\(p(x)=\\frac{e^{-\\lambda}\\cdot\\lambda^x}{x!},\\;x=0,1,...\\) Exemplo: Em um certo pedágio, passam em média 50 carros em uma manhã qualquer, qual a probabilidade de passar 60 carros em uma manhã? \\[ \\begin{align*} p(60)=\\frac{e^{-50}\\cdot\\lambda^{60}}{60!}= \\end{align*} \\] 10.2 Modelos Contínuos 10.2.1 Modelo Uniforme Contínuo Diremos que \\(X\\) segue um modelo uniforme contínuo no intervalo \\([a,b]\\subset\\mathbb{R}\\) se todos os subintervalos de \\([a,b]\\) de mesmo comprimento tenham a mesma probabilidade. Notação: \\(X\\sim U[a,b]\\) Função de Densidade: \\(f(x)=\\frac1{b-a},\\;a\\le x\\le b\\) Exemplo: em um programa de TV que dura 1 hora, o telespectador pode mudar de canal a qualquer momento. Qual a probabilidade de que o telespectador assista a maior parte do programa. Solução: \\(X\\sim U[0,1]\\)Assistir a maior parte significa assistir mais de \\(\\frac12\\) do programa, portanto queremos \\(P(X&gt;\\frac12)\\), podemos resolver essa probabilidade de maneira geométrica. A área que queremos obter é a área entre \\(\\frac12\\) e \\(1\\): É fácil notar que a área do retângulo é \\(\\frac12\\cdot1=\\frac12\\), portanto \\(P(X&gt;\\frac12)=\\frac12\\). 10.2.2 Modelo Exponencial Suponha que queremos determinar o tempo de espera para o ocorrência de um evento. Então usaremos uma distribuição exponencial de parâmetro \\(\\lambda\\) onde \\(\\lambda\\) representa a taxa de ocorrência do evento por unidade de medida. Notação: \\(X\\sim exp(\\lambda)\\) Função de Densidade: \\(f(x)=\\lambda e^{-\\lambda x},\\;x&gt;0\\) Exemplo: Um call center recebe chamadas telefônicas a cada \\(X\\) horas, a taxa de ocorrência por hora é de 5 chamadas. Qual a probabilidade de um intervalo entre chamadas ser inferior a 30 minutos? \\[ \\begin{align*} &amp;X\\sim exp(5)\\\\ &amp;f(x)=5e^{-5x},\\;x&gt;0\\\\ &amp;P(X&lt;\\frac12)=\\int_0^\\frac125e^{-5x}dx=-e^{-5x}|_0^\\frac12\\\\ &amp;=1-e^\\frac52=0,918 \\end{align*} \\] 10.2.3 Modelo Normal Uma variável aleatória \\(X\\) segue um modelo normal se sua função de densidade é a seguinte: \\[ \\begin{align*} &amp;f(x)=\\frac1{\\sigma\\sqrt{2\\pi}}e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}},\\;x\\in\\mathbb{R} \\end{align*} \\] Os parâmetros \\(\\mu\\) e \\(\\sigma\\) representam respectivamente a média e variância da distribuição. A função de distribuição da Normal não possui forma fechada pois sua integral não possui primitiva. E, também, integrar sua função de densidade para encontrar probabilidades não é algo trivial. Portando, usaremos uma técnica chamada padronização. Proposição: Seja \\(X\\sim N(\\mu, \\sigma^2)\\text{, então } Z=\\frac{X-\\mu}{\\sigma}\\) terá distribuição \\(N(0,1)\\). Assim, para encontrar as probabilidades de interesse em uma Normal qualquer, encontraremos a probabilidade equivalente em uma \\(N(0,1)\\) (chamada “Normal Padrão”). Os valores da função de distribuição da Normal Padrão são representados por \\(\\Phi(z)\\), e estão organizados em uma tabela para auxiliar nos cálculos de probabilidade. \\[ \\begin{align*} &amp;X\\sim N(\\mu,\\sigma^2)\\\\ &amp;Z=\\frac{X-\\mu}\\sigma\\sim N(0,1)\\\\ &amp;P(a\\le X\\le b) = P(\\frac{a-\\mu}\\sigma\\le Z\\le\\frac{b-\\mu}\\sigma)= \\Phi(\\frac{b-\\mu}\\sigma)-\\Phi(\\frac{a-\\mu}\\sigma) \\end{align*} \\] "],["funções-de-variáveis-aleatórias.html", "Chapter 11 FUNÇÕES DE VARIÁVEIS ALEATÓRIAS 11.1 Esperança de Função de V.a’s 11.2 Distribuição de Funções de V.a’s 11.3 Jacobiano", " Chapter 11 FUNÇÕES DE VARIÁVEIS ALEATÓRIAS 11.1 Esperança de Função de V.a’s É claro que, dada uma v.a \\(X\\) a função \\(Y=g(X)\\) também será uma v.a desde que g seja uma função apropriada(mensurável). Exemplo: Seja \\(X\\) uma v.a tal que \\(P(X=-1)=P(X=1)=\\frac{1}{2}\\). Defina a função \\(Y=X²\\), então \\(Y=X²\\) também será uma v.a no mesmo e.p com f.p dada por \\(P(Y=1)=1\\), ou seja, \\(Y\\) é massa pontual em 1. (notar que: \\(E(X²)=E(Y)=1\\cdot P(Y=1)=1\\)) Definição: Seja \\(X\\) uma v.a em \\((\\Omega,\\mathbb{A},P)\\) e seja \\(Y=g(X)\\) uma função mensurável em \\(\\mathbb{R}\\). Então: \\[ \\begin{align*} &amp;E(Y)=E\\left[g(X)\\right]=\\int g(x)dF(x)= \\left\\{ \\begin{array}{ll} \\underset{x}{\\sum}g(x)P(X=x),&amp;X\\text{ discreto}\\\\ \\overset{+\\infty}{\\underset{-\\infty}{\\int}}g(x)f(x)dx,&amp;X\\text{ contínua} \\end{array} \\right. \\end{align*} \\] Um caso importante de função de v.a é \\(g(x)=x^k,\\;k=1,2,3,...\\) Definição: Seja X uma v.a. O valor \\(E(X-b)^k\\), se existir, é chamado k-ésimo momento de \\(X\\) em torno de \\(b\\), para \\(b\\in\\mathbb{R},k=1,2,...\\) O k-ésimo momento de \\(X\\) em torno de zero, \\(E(X^k)\\), é chamdo simplesmente de k-ésimo momento de X ou momento de ordem \\(k\\). O k-ésimo momento de \\(X\\) em torno de sua média,\\(E(X-E(X))^k\\), é chamado k-ésimo momento central de \\(X\\) obs: \\[ \\begin{align*} &amp;1)\\text{ O primeiro momento de X é }E(X)\\\\ &amp;2)\\text{ O primeiro momento central é zero, pois: }\\\\ &amp;\\quad E(X-E(X))=E(X)-E(E(X))=E(X)-E(X)=0\\\\ &amp;3)\\text{ O segundo momento central será a variância:}\\\\ &amp;\\quad\\text{Prova: }E(X-E(X))²=E(X²-2XE(X)+[E(X)]²)\\\\ &amp;\\qquad\\qquad =E(X²)-2E(X)E(X)+[E(X)]²\\\\ &amp;\\qquad\\qquad =E(X²)-2[E(X)]²+[E(X)]²\\\\ &amp;\\qquad\\qquad =E(X²)-[E(X)]²=Var(X) \\end{align*} \\] Definição: Define-se o desvio padrão de \\(X\\) como a raiz positiva da variância:\\(\\Large\\sigma\\normalsize_X=\\sqrt{Var(X)}\\) Proposição: \\[ \\begin{align*} &amp;1)\\text{ Se }X=c,\\text{ entâo } Var(X)=0\\\\ &amp;2)\\;Var(X+b)=Var(X)\\text{ e }Var(aX+b)=a²Var(X)\\\\ &amp;3)\\text{ Desigualdade básica. Se X é uma v.a,não negativa então:}\\\\ &amp;\\quad P(X\\ge\\lambda)\\le\\frac{1}{\\lambda}E(X),\\;\\forall\\lambda&gt;0\\\\ &amp;4)\\text{ Desiqualdade clássica de Tchebychev. Se X é integrável, então:}\\\\ &amp;\\quad P(|X-E(X)|\\ge\\lambda)\\le\\frac{Var(X)}{\\lambda²},\\;\\forall\\lambda&gt;0\\\\ &amp;5)\\text{ Desigualdade de Markov. Para qualquer v.a X:}\\\\ &amp;\\quad P(|X|\\ge\\lambda)\\le\\frac{E|X|^t}{\\lambda^t},\\;\\forall\\lambda&gt;0,t&gt;0 \\end{align*} \\] Proposição: Seja \\(X\\) integrável com \\(E(X)=\\mu\\). Então, \\(\\mu\\) é o valor que minimiza \\(E(X-c)²,\\;c\\in\\mathbb{R}\\). Ou seja, \\(Var(X)=E(X-E(X))²=\\underset{c}{\\min}E(X-c)²\\) 11.2 Distribuição de Funções de V.a’s Dada uma v.a \\(X\\) com distribuição conhecida e dada uma transformação \\(Y=g(X)\\), sendo \\(g\\) enumerável. O objetivo é encontrar a distribuição de \\(Y\\) a partir da distribuição de \\(X\\). 11.2.1 Caso discreto Seja \\(X\\) v.a discreta em \\(\\{x_1,x_2,...\\}\\) Seja \\(Y=g(X) \\rightarrow Y\\in\\{g(x_1),g(x_2),...\\}\\) Então: \\[ \\begin{align*} &amp;P(Y=y)=P(g(x)=y)=P(X=g^{-1}(y)) \\end{align*} \\] Exemplo: Seja \\(X\\) com a seguinte distribuição: \\[ \\begin{array}{l|l|l|l|} X&amp;-2&amp;-1&amp;0&amp;2\\\\ \\hline P_X&amp;\\frac{1}{8}&amp;\\frac{1}{4}&amp;\\frac{1}{2}&amp;\\frac{1}{8}\\\\ \\end{array} \\] Defina a nova v.a \\(Y=g(X)=X²\\), vemos que \\(Y\\in\\{0,1,4\\}\\). \\[ \\begin{align*} &amp;P(Y=0)=P(X=0)=\\frac{1}{2}\\\\ &amp;P(Y=1)=P(X=-1)=\\frac{1}{4}\\\\ &amp;P(Y=4)=P(X=-2)+P(X=2)=\\frac{1}{8}+\\frac{1}{8}=\\frac{1}{4} \\end{align*} \\] Seja \\(U=1+\\cos(\\pi X)\\). \\(U\\in\\{0,2\\}\\) \\[ \\begin{align*} &amp;\\begin{array}{l|l|l|l|} X&amp;-2&amp;-1&amp;0&amp;2\\\\ \\hline P_X&amp;\\frac{1}{8}&amp;\\frac{1}{4}&amp;\\frac{1}{2}&amp;\\frac{1}{8}\\\\ \\hline U&amp;2&amp;0&amp;2&amp;2\\\\ \\hline \\end{array}\\\\ \\\\ &amp;P(U=0)=P(X=-1)=\\frac{1}{4}\\\\ &amp;P(U=2)=1-P(U=0)=\\frac{3}{4} \\end{align*} \\] Exemplo: Seja \\(X\\sim Geo(p),\\;x=0,1,2,...\\) \\[ \\begin{align*} &amp;P(X=x)=p(1-p)^x\\quad,x=0,1,2,... \\end{align*} \\] Seja \\(Y=X+1\\rightarrow Y\\in\\{1,2,3,...\\}\\) \\[ \\begin{align*} &amp;\\overset{P_Y(y)}{P(Y=y)}=P(X+1=y)=\\overset{P_X(y-1)}{P(X=y-1)}\\\\ &amp;\\qquad\\qquad=p(1-p)^{y-1}\\;,\\;y=1,2,3,...\\\\ &amp;\\text{Portanto:}\\\\ &amp;\\qquad\\qquad Y\\sim Geo(p)\\;,\\;y=1,2,3,... \\end{align*} \\] 11.2.2 Caso contínuo Exemplo: Seja \\(X\\sim U(0,1)\\) \\[ \\begin{align*} &amp;f_X(x)=1,\\quad 0&lt;x&lt;1\\\\ &amp;F_X(x)=x,\\quad 0&lt;x&lt;1 \\end{align*} \\] Defina \\(Y=-\\ln{X}\\) \\[ \\begin{align*} &amp;F_Y(y)=P(Y\\le y)=P(-\\ln{X}\\le y)=P(\\ln{X}\\ge -y)=P(X\\ge e^{-y})\\\\ &amp;=1-P(X\\le e^{-y})=1-F_X(e^{-y})=1-e^{-y}\\\\ &amp;\\text{pois, }0&lt;e^{-y}&lt;1 \\text{ se } y&gt;0 \\end{align*} \\] Assim, \\(F_Y(y)=1-e^{-y},\\quad y&gt;0.\\) \\(\\rightarrow Y\\sim \\exp(1)\\) 11.3 Jacobiano Teorema: Seja \\(X\\) uma v.a contínua com densidade \\(f_X(x)\\). Seja \\(Y\\) a transformação:\\(Y=g(X)\\), com g sendo bijetora sobre alguma região aberta. Então: \\[ \\begin{align*} &amp;f_Y(y)=f_X(g^{-1}(y))|J(x,y)| \\end{align*} \\] sendo \\(J(x,y)=\\frac{dx}{dy}=\\frac{d\\left[g^{-1}(y)\\right]}{dy}\\), chamado o Jacobiano de transformação. Exemplo_1: Se \\(Y=g(X)\\) \\[ \\begin{align*} &amp;F_Y(y)=P(Y\\le y)=P(g(X)\\le y)=\\overset{\\text{se }g^{-1}\\text{ existe}}{P(X\\le g^{-1}(y))}=F_X(g^{-1}(y))\\\\ &amp;F_Y(y)=F_X(g^{-1}(y))\\\\ &amp;\\text{Derivando ambos os membros:}\\\\ &amp;f_Y(y)=f_X(g^{-1}(y))\\left|\\left[g^{-1}(y)\\right]&#39;\\right| \\end{align*} \\] do exemplo contínuo: \\[ \\begin{align*} &amp;f_X(x)=1,\\quad 0&lt;x&lt;1\\qquad\\qquad\\qquad y=g(x)=-\\ln X\\rightarrow x=g^{-1}(y)=e^{-y}\\\\ &amp;\\text{Assim,}\\\\ &amp;f_Y(y)=f_X(e^{-y})\\left|\\left[e^{-y}\\right]&#39;\\right|=e^{-y},\\quad y&gt;0 \\end{align*} \\] Exemplo_2: Seja \\(X\\sim N(0,1)\\) e seja \\(Y=X²\\). Encontrar a distribuição de \\(Y\\). \\[ \\begin{align*} &amp;f_X(x)=\\frac{1}{\\sqrt{2\\pi}}{\\Large e^{-\\frac{x²}{2}},\\quad x\\in\\mathbb{R}} \\end{align*} \\] como \\(Y=g(X)=X^2\\), então existem duas inversas, dependendo da região. Nesse caso, define-se: \\[ \\begin{align*} &amp;g_1^{-1}(y)=-\\sqrt{y}\\quad\\text{e}\\quad g_2^{-1}(y)=\\sqrt{y} \\qquad J_1(x,y)=\\frac{-1}{2\\sqrt{y}}\\quad\\text{e}\\quad J_2(x,y)=\\frac{1}{2\\sqrt{y}}\\\\ \\\\ &amp;f_Y(y)=f_X(g_1^{-1}(y))|J_1|+f_X(g_2^{-1}(y))|J_2|\\\\ &amp;=\\frac{1}{\\sqrt{2\\pi}}{\\Large e^\\frac{{-\\left[-\\sqrt{y}\\right]²}}{2}}\\left|\\frac{-1}{2\\sqrt{y}}\\right|+ \\frac{1}{\\sqrt{2\\pi}}{\\Large e^\\frac{{-\\left[\\sqrt{y}\\right]²}}{2}}\\left|\\frac{1}{2\\sqrt{y}}\\right|= 2\\frac{1}{\\sqrt{2\\pi}}{\\Large e^{\\frac{-y}{2}}}\\frac{1}{2\\sqrt{y}}=\\frac{1}{\\sqrt{2\\pi y}}{\\Large e^{\\frac{-y}{2}}},\\quad y&gt;0\\\\ &amp;\\text{Assim: }Y\\sim{\\large\\chi}^{2}_{(1)} \\end{align*} \\] Se \\(X_1,X_2,...,X_n\\) são iid \\(N(0,1)\\;\\longrightarrow X^{2}_{1}+X^{2}_{2}+...+X^{2}_{n}\\sim{\\large\\chi}^{2}_{(n)}\\) "],["references.html", "References", " References "]]
